<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Privacidad de los Datos</title>
  <link rel="stylesheet" href="style.css">
  <script src="script.js"></script>
</head>
<body class="inicio">
  <div class="container">
    <aside class="sidebar">
      <button class="paper-btn" onclick="irAPagina('index.html')">Inicio</button>
      <button class="paper-btn" onclick="irAPagina('privacidad.html')">Privacidad de Datos</button>
      <button class="paper-btn" onclick="irAPagina('etica.html')">Uso Ético Laboral</button>
      <button class="paper-btn" onclick="irAPagina('relacion.html')">Relación entre Temas</button>
      <button class="paper-btn" onclick="irAPagina('conclusion.html')">Conclusión</button>
    </aside>
    <main class="main-content">
      <h1>Privacidad de los Datos en la Inteligencia Artificial</h1>

      <img src="privacidad.jpg.jpg" alt="Imagen representativa de la IA" class="img-inicio">

      <section>
        <h2>¿Qué significa la privacidad en la IA?</h2>
        <p class="intro">La privacidad de los datos se refiere a la protección de la información personal que los sistemas inteligentes utilizan para aprender y tomar decisiones. Cada vez que una persona usa una app, red social o servicio digital, genera huellas de datos que pueden ser almacenadas, analizadas o incluso vendidas.</p>
        <p class="intro">La inteligencia artificial depende de grandes cantidades de información (big data) para funcionar correctamente. Sin embargo, este proceso puede comprometer la privacidad individual si no existen controles adecuados sobre qué datos se recopilan, cómo se usan y quién los administra.</p>
      </section>

      <section>
        <h2>¿Por qué la privacidad es un tema ético?</h2>
        <ul class="intro">
          <li>Un sistema de reconocimiento facial puede identificar a una persona sin su consentimiento.</li>
          <li>Los algoritmos de recomendación pueden deducir preferencias políticas, religiosas o de salud.</li>
          <li>Un modelo de IA puede tomar decisiones que afecten a una persona (como rechazar un crédito o una oferta laboral) basándose en información incompleta o sesgada.</li>
        </ul>
        <p class="intro">Estos casos plantean dilemas éticos sobre la autonomía, la seguridad y el derecho a la intimidad. Proteger los datos no solo es una cuestión técnica, sino moral y legal, porque involucra los derechos humanos digitales.</p>
      </section>

      <section>
        <h2>Principios éticos del manejo de datos</h2>
        <ol class="intro">
          <li><strong>Legalidad:</strong> los datos deben obtenerse de forma lícita y respetando la normativa vigente.</li>
          <li><strong>Consentimiento informado:</strong> las personas deben saber para qué se recopilan sus datos y autorizar su uso.</li>
          <li><strong>Finalidad específica:</strong> la información solo puede usarse con el propósito para el cual fue recolectada.</li>
          <li><strong>Proporcionalidad:</strong> solo deben recolectarse los datos estrictamente necesarios.</li>
          <li><strong>Seguridad:</strong> garantizar la protección frente a accesos no autorizados o filtraciones.</li>
          <li><strong>Transparencia:</strong> las empresas deben explicar claramente cómo usan los datos.</li>
          <li><strong>Responsabilidad:</strong> quien maneja los datos debe responder ante posibles daños o abusos.</li>
        </ol>
      </section>

      <section>
        <h2>La ley argentina y la protección de datos</h2>
        <p class="intro">En Argentina, la Ley N° 25.326 de Protección de Datos Personales regula el uso y almacenamiento de información sensible. Su objetivo es proteger el derecho a la intimidad y asegurar que las personas puedan acceder, corregir o eliminar sus datos personales cuando sea necesario.</p>
        <p class="intro">Esta ley también prohíbe el uso de información para fines distintos a los consentidos y exige que las bases de datos estén debidamente registradas ante la autoridad competente.</p>
        <p class="intro">Cuando se aplica a la inteligencia artificial, la ley busca evitar que los algoritmos tomen decisiones sin supervisión humana o que discriminen mediante el análisis automático de información personal.</p>
      </section>

      <section>
        <h2>Riesgos actuales</h2>
        <ul class="intro">
          <li><strong>Vigilancia digital:</strong> monitoreo constante mediante cámaras, sensores o redes sociales.</li>
          <li><strong>Filtraciones de datos:</strong> vulnerabilidades en sistemas que exponen información personal.</li>
          <li><strong>Sesgos algorítmicos:</strong> modelos de IA que refuerzan prejuicios al analizar datos históricos.</li>
          <li><strong>Pérdida de anonimato:</strong> los datos anonimizados pueden cruzarse con otros y volver a identificar personas.</li>
        </ul>
        <p class="intro">Por eso, es esencial implementar políticas de seguridad cibernética, auditorías éticas y una educación digital que fomente el uso responsable de la información.</p>
      </section>

      <section>
        <h2>La importancia de la confianza digital</h2>
        <p class="intro">La privacidad no debe verse como un obstáculo, sino como un pilar de la confianza en la tecnología. Los usuarios deben sentirse seguros al compartir información, sabiendo que sus datos serán usados con ética y responsabilidad.</p>
        <p class="intro">Cuando la IA se desarrolla respetando la privacidad, se promueve una relación más sana entre las personas y la tecnología, basada en la transparencia, el respeto y la seguridad.</p>
      </section>

      <section>
        <h2>Conclusión</h2>
        <p class="intro">La privacidad de los datos en la inteligencia artificial es uno de los mayores desafíos del presente. Garantizarla requiere un equilibrio entre el avance tecnológico y la protección de los derechos humanos. Una IA ética debe ser capaz de aprender sin invadir la intimidad de las personas, aplicando principios de legalidad, transparencia y responsabilidad social.</p>
      </section>

      <a class="volver" href="index.html">Volver al inicio</a>
    </main>
  </div>
  <footer>
        <p>© 2025 - Proyecto académico realizado por Martínez, Nievas y Pared</p>
    </footer>
</body>
</html>
