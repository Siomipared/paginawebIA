<!DOCTYPE html>
<html lang="es-AR">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Relación entre Privacidad y Ética en la IA</title>
  <link rel="stylesheet" href="style.css">
  <script src="script.js"></script>
</head>
<body class="inicio">

    <div class="container">
        
        <!-- Barra lateral con los botones -->
        <aside class="sidebar">
            <button class="paper-btn" onclick="irAPagina('index.html')">Inicio</button>
            <button class="paper-btn" onclick="irAPagina('privacidad.html')">Privacidad de Datos</button>
            <button class="paper-btn" onclick="irAPagina('etica.html')">Uso Ético Laboral</button>
            <button class="paper-btn" onclick="irAPagina('relacion.html')">Relación entre Temas</button>
            <button class="paper-btn" onclick="irAPagina('conclusion.html')">Conclusión</button>
        </aside>
        <main class="main-content">
          <h1>Relación entre la Privacidad de los Datos y el Uso Ético de la Inteligencia Artificial</h1>
          <div class="section">
              <h2>Privacidad de datos</h2>
              <p class="intro">Es importante proteger la información personal de los usuarios.</p>
              <p class="intro">Todos los datos recolectados se almacenan de manera segura.</p>
            </div>
            
          <section>
            <h2>Una conexión inseparable</h2>
            <p class="intro">La privacidad de los datos y el uso ético de la inteligencia artificial están profundamente relacionados. La IA necesita grandes volúmenes de información para funcionar, pero esa información proviene de personas reales, con derechos y libertades que deben ser respetados.</p>
            <p class="intro">Por eso, no se puede hablar de ética en la IA sin hablar de protección de datos personales. Ambos temas comparten un mismo objetivo: garantizar que la tecnología sirva al bienestar humano, y no lo contrario.</p>
          </section>

          <section>
            <h2>Datos, decisiones y responsabilidad</h2>
            <p class="intro">Cada vez que un sistema de IA toma una decisión —como recomendar contenido, evaluar candidatos o analizar comportamientos— lo hace a partir de datos recopilados de usuarios o trabajadores. Si esos datos son incorrectos, están sesgados o fueron obtenidos sin consentimiento, el resultado será injusto y poco ético.</p>
            <ul class="intro">
              <li>Un algoritmo de contratación que use datos históricos puede discriminar a mujeres si la empresa en el pasado contrató más hombres.</li>
              <li>Un sistema de seguridad con reconocimiento facial puede violar la privacidad al identificar personas sin su permiso.</li>
            </ul>
            <p class="intro">Esto demuestra que la calidad y el origen de los datos son claves para asegurar un uso ético de la IA.</p>
          </section>

          <section>
            <h2>Ética, privacidad y justicia tecnológica</h2>
            <p class="intro">La justicia tecnológica se basa en el principio de que todas las personas deben beneficiarse de la tecnología en igualdad de condiciones. Para lograrlo, las instituciones deben aplicar políticas que respeten la privacidad y eviten la discriminación algorítmica.</p>
            <ul class="intro">
              <li>Diseñar algoritmos transparentes y auditables.</li>
              <li>Explicar de forma clara cómo se utilizan los datos.</li>
              <li>Permitir a los usuarios controlar su información personal.</li>
              <li>Garantizar que ninguna persona sea afectada por decisiones automatizadas sin intervención humana.</li>
            </ul>
          </section>

          <section>
            
            <h2>La importancia del consentimiento y la transparencia</h2>
            <p class="intro">El consentimiento informado es uno de los pilares éticos en la relación entre IA y privacidad. Las personas deben saber:</p>
            <ul class="intro">
              <li>Qué datos se recopilan.</li>
              <li>Con qué propósito se utilizan.</li>
              <li>Durante cuánto tiempo se almacenan.</li>
              <li>Quién tiene acceso a ellos.</li>
            </ul>
            <p class="intro">Sin esta transparencia, la confianza digital desaparece, y la tecnología puede volverse invasiva o manipuladora.</p>
          </section>

          <section>
            <h2>Impacto social y responsabilidad colectiva</h2>
            <p class="intro">El uso masivo de la IA afecta a toda la sociedad, por eso la responsabilidad no recae solo en los programadores o empresas, sino también en los gobiernos, instituciones educativas y usuarios. Promover una IA ética y respetuosa con la privacidad implica educar, regular y participar activamente en la creación de políticas tecnológicas responsables.</p>
            <p class="intro">La colaboración entre el ámbito científico, político y social es fundamental para construir un entorno digital más seguro, justo y humano.</p>
          </section>

          <section>
            <h2>Conclusión</h2>
            <p class="intro">La privacidad de los datos y el uso ético de la IA son dos caras de una misma moneda. Sin privacidad, no hay ética; sin ética, no hay confianza en la tecnología. Ambos valores deben coexistir para que la inteligencia artificial contribuya verdaderamente al desarrollo humano, protegiendo la dignidad, los derechos y la libertad de cada individuo.</p>
          </section>

          <a class="volver" href="index.html">Volver al inicio</a>
        </main>
    </div>
    <footer>
        <p>© 2025 - Proyecto académico realizado por Martínez, Nievas y Pared</p>
    </footer>
</body>
</html>
