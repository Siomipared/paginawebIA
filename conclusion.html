<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Conclusión - Ética en la Inteligencia Artificial</title>
  <link rel="stylesheet" href="style.css">
  <script src="script.js"></script>
</head>
<body class="inicio">

    <div class="container">
        
        <!-- Barra lateral con los botones -->
        <aside class="sidebar">
            <button class="paper-btn" onclick="irAPagina('index.html')">Inicio</button>
            <button class="paper-btn" onclick="irAPagina('privacidad.html')">Privacidad de Datos</button>
            <button class="paper-btn" onclick="irAPagina('etica.html')">Uso Ético Laboral</button>
            <button class="paper-btn" onclick="irAPagina('relacion.html')">Relación entre Temas</button>
            <button class="paper-btn" onclick="irAPagina('conclusion.html')">Conclusión</button>
        </aside>
        <main class="main-content">
          <h1>Conclusión Final</h1>

          <section>
            <h2>Reflexión final</h2>
            <p class="intro">La inteligencia artificial se ha convertido en una herramienta esencial en la sociedad moderna, capaz de optimizar procesos, mejorar la toma de decisiones y facilitar la vida cotidiana. Sin embargo, su crecimiento acelerado plantea desafíos que no pueden ser ignorados: la pérdida de privacidad, la automatización del trabajo y la falta de regulación ética.</p>
            <p class="intro">La tecnología por sí sola no es buena ni mala; todo depende del uso y la intención humana detrás de ella. Por eso, es fundamental promover una IA transparente, responsable y centrada en las personas, que respete los valores fundamentales de la sociedad: dignidad, libertad, justicia y equidad.</p>
          </section>

          <section>
            <h2>Hacia una inteligencia artificial ética y humana</h2>
            <p class="intro">Para alcanzar un desarrollo tecnológico sostenible, es necesario construir una cultura digital basada en tres pilares principales:</p>
            <ol class="intro">
              <li><strong>Privacidad:</strong> proteger los datos personales y garantizar que cada individuo conserve el control sobre su información.</li>
              <li><strong>Responsabilidad:</strong> desarrollar tecnologías que rindan cuentas por sus decisiones y resultados.</li>
              <li><strong>Educación ética:</strong> formar ciudadanos y profesionales conscientes del impacto de la IA en la vida social y laboral.</li>
            </ol>
            <p class="intro">Solo a través del compromiso conjunto entre científicos, empresas, gobiernos y usuarios se logrará una IA que sirva al bien común y no vulnere los derechos humanos.</p>
          </section>

          <section>
            <h2>Fuentes consultadas</h2>
            <ul class="intro">
              <li>UNESCO (2023). <em>Principios éticos en la inteligencia artificial.</em></li>
              <li>Ley 25.326 de Protección de Datos Personales (Argentina).</li>
              <li>Revista CTS (2024). <em>Ética y automatización en el trabajo.</em></li>
              <li>Ministerio de Ciencia, Tecnología e Innovación Productiva (Argentina). <em>Guía para el desarrollo responsable de la IA.</em></li>
              <li>IBM Research (2023). <em>Artificial Intelligence and Data Privacy: Global Perspectives.</em></li>
            </ul>
          </section>

          <h2>Autoras del proyecto</h2>
          <section class="intro">
            <p><strong>Alumnas:</strong> Valentina Martínez, Silvina Nievas, Priscila Pared</p>
            <p><strong>Profesora:</strong> Romina Miranda</p>
            <p><strong>Materia:</strong> Ciencia, Tecnología y Sociedad</p>
            <p><strong>Fecha:</strong> 7 de octubre de 2025</p>
            <p><strong>Instituto:</strong> IESET y FP – Educación Técnica y Formación Profesional</p>
          </section>

          <a class="volver" href="index.html">Volver al inicio</a>
        </main>
    </div>
    <footer>
        <p>© 2025 - Proyecto académico realizado por Martínez, Nievas y Pared</p>
    </footer>
</body>
</html>
